<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8"/>
	<link rel="stylesheet" type="text/css" href="style.css"/>
	<title>MOVDQU—Move Unaligned Double Quadword</title>
</head>
<body>
<h1 id="movdqu-move-unaligned-double-quadword">MOVDQU—Move Unaligned Double Quadword</h1>
<table>
<tr>
	<td>Opcode/Instruction</td>
	<td>Op/En</td>
	<td>64/32-bit Mode</td>
	<td>CPUID Feature Flag</td>
	<td>Description</td>
</tr>
<tr>
	<td>F3 0F 6F /<em>r</em> MOVDQU <em>xmm1</em>, <em>xmm2/m128</em></td>
	<td>RM</td>
	<td>V/V</td>
	<td>SSE2</td>
	<td>Move unaligned double quadword from <em>xmm2/m128</em> to <em>xmm1</em>.</td>
</tr>
<tr>
	<td>F3 0F 7F /<em>r</em> MOVDQU <em>xmm2/m128</em>, <em>xmm1</em></td>
	<td>MR</td>
	<td>V/V</td>
	<td>SSE2</td>
	<td>Move unaligned double quadword from <em>xmm1</em> to <em>xmm2/m128</em>.</td>
</tr>
<tr>
	<td>VEX.128.F3.0F.WIG 6F /r VMOVDQU <em>xmm1, xmm2/m128</em></td>
	<td>RM</td>
	<td>V/V</td>
	<td>AVX</td>
	<td>Move unaligned packed integer values from <em>xmm2/mem</em> to <em>xmm1</em>.</td>
</tr>
<tr>
	<td>VEX.128.F3.0F.WIG 7F /r VMOVDQU <em>xmm2/m128, xmm1</em></td>
	<td>MR</td>
	<td>V/V</td>
	<td>AVX</td>
	<td>Move unaligned packed integer values from <em>xmm1</em> to <em>xmm2/mem</em>.</td>
</tr>
<tr>
	<td>VEX.256.F3.0F.WIG 6F /r VMOVDQU <em>ymm1, ymm2/m256</em></td>
	<td>RM</td>
	<td>V/V</td>
	<td>AVX</td>
	<td>Move unaligned packed integer values from <em>ymm2/mem</em> to <em>ymm1</em>.</td>
</tr>
<tr>
	<td>VEX.256.F3.0F.WIG 7F /r VMOVDQU <em>ymm2/m256, ymm1</em></td>
	<td>MR</td>
	<td>V/V</td>
	<td>AVX</td>
	<td>Move unaligned packed integer values from <em>ymm1</em> to <em>ymm2/mem</em>.</td>
</tr>
</table>
<h2 id="instruction-operand-encoding">Instruction Operand Encoding</h2>
<table>
<tr>
	<td>Op/En</td>
	<td>Operand 1</td>
	<td>Operand 2</td>
	<td>Operand 3</td>
	<td>Operand 4</td>
</tr>
<tr>
	<td>RM</td>
	<td>ModRM:reg (w)</td>
	<td>ModRM:r/m (r)</td>
	<td>NA</td>
	<td>NA</td>
</tr>
<tr>
	<td>MR</td>
	<td>ModRM:r/m (w)</td>
	<td>ModRM:reg (r)</td>
	<td>NA</td>
	<td>NA</td>
</tr>
</table>
<h2 id="description">Description</h2>
<p>128-bit versions:</p>
<p>Moves 128 bits of packed integer values from the source operand (second operand) to the destination operand (first operand). This instruction can be used to load an XMM register from a 128-bit memory location, to store the contents of an XMM register into a 128-bit memory location, or to move data between two XMM registers. When the source or destination operand is a memory operand, the operand may be unaligned on a 16-byte boundary without causing a general-protection exception (#GP) to be generated.<sup>1</sup></p>
<p>To move a double quadword to or from memory locations that are known to be aligned on 16-byte boundaries, use the MOVDQA instruction.</p>
<p>While executing in 16-bit addressing mode, a linear address for a 128-bit data access that overlaps the end of a 16bit segment is not allowed and is defined as reserved behavior. A specific processor implementation may or may not generate a general-protection exception (#GP) in this situation, and the address that spans the end of the segment may or may not wrap around to the beginning of the segment.</p>
<p>In 64-bit mode, use of the REX.R prefix permits this instruction to access additional registers (XMM8-XMM15). 128-bit Legacy SSE version: Bits (VLMAX-1:128) of the corresponding YMM destination register remain unchanged. When the source or destination operand is a memory operand, the operand may be unaligned to any alignment without causing a general-protection exception (#GP) to be generated VEX.128 encoded version: Bits (VLMAX-1:128) of the destination YMM register are zeroed.</p>
<p>VEX.256 encoded version: Moves 256 bits of packed integer values from the source operand (second operand) to the destination operand (first operand). This instruction can be used to load a YMM register from a 256-bit memory</p>
<table>
<tr>
	<td>1.</td>
	<td>If alignment checking is enabled (CR0.AM = 1, RFLAGS.AC = 1, and CPL = 3), an alignment-check exception (#AC) may or may not be generated (depending on processor implementation) when the operand is not aligned on an 8-byte boundary.</td>
</tr>
</table>
<p>location, to store the contents of a YMM register into a 256-bit memory location, or to move data between two YMM registers. Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.</p>
<h2 id="operation">Operation</h2>
<pre>MOVDQU load and register copy (128-bit Legacy SSE version)
DEST[127:0] ← SRC[127:0]
DEST[VLMAX-1:128] (Unmodified)
(V)MOVDQU 128-bit store-form versions
DEST[127:0] ← SRC[127:0]
VMOVDQU (VEX.128 encoded version)
DEST[127:0] ← SRC[127:0]
DEST[VLMAX-1:128] ← 0
VMOVDQU (VEX.256 encoded version)
DEST[255:0] ← SRC[255:0]
</pre>
<h2 id="intel-c-c-compiler-intrinsic-equivalent">Intel C/C++ Compiler Intrinsic Equivalent</h2>
<table>
<tr>
	<td>MOVDQU:</td>
	<td>void _mm_storeu_si128 ( __m128i *p, __m128i a)</td>
</tr>
<tr>
	<td>MOVDQU:</td>
	<td>__m128i _mm_loadu_si128 ( __m128i *p)</td>
</tr>
<tr>
	<td>VMOVDQU:</td>
	<td>__m256i _mm256_loadu_si256 (__m256i * p);</td>
</tr>
<tr>
	<td>VMOVDQU:</td>
	<td>_mm256_storeu_si256(_m256i *p, __m256i a);</td>
</tr>
</table>
<h2 id="simd-floating-point-exceptions">SIMD Floating-Point Exceptions</h2>
<p>None.</p>
<h2 id="other-exceptions">Other Exceptions</h2>
<p>See Exceptions Type 4; additionally</p>
<table>
<tr>
	<td>#UD</td>
	<td>If VEX.vvvv != 1111B.</td>
</tr>
</table>
</body>
</html>
