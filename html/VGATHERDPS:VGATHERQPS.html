<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8"/>
	<link rel="stylesheet" type="text/css" href="style.css"/>
	<title>VGATHERDPS/VGATHERQPS — Gather Packed SP FP values Using Signed Dword/Qword Indices</title>
</head>
<body>
<h1 id="vgatherdps-vgatherqps-gather-packed-sp-fp-values-using-signed-dword-qword-indices">VGATHERDPS/VGATHERQPS — Gather Packed SP FP values Using Signed Dword/Qword Indices</h1>
<table>
<tr>
	<td>Opcode/Instruction</td>
	<td>Op/En</td>
	<td>64/32 -bit Mode</td>
	<td>CPUID Feature Flag</td>
	<td>Description</td>
</tr>
<tr>
	<td>VEX.DDS.128.66.0F38.W0 92 /r VGATHERDPS <em>xmm1, vm32x, xmm2</em></td>
	<td>RMV</td>
	<td>V/V</td>
	<td>AVX2</td>
	<td>Using dword indices specified in <em>vm32x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>
</tr>
<tr>
	<td>VEX.DDS.128.66.0F38.W0 93 /r VGATHERQPS <em>xmm1, vm64x, xmm2</em></td>
	<td>RMV</td>
	<td>V/V</td>
	<td>AVX2</td>
	<td>Using qword indices specified in <em>vm64x</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>
</tr>
<tr>
	<td>VEX.DDS.256.66.0F38.W0 92 /r VGATHERDPS <em>ymm1, vm32y, ymm2</em></td>
	<td>RMV</td>
	<td>V/V</td>
	<td>AVX2</td>
	<td>Using dword indices specified in <em>vm32y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td>
</tr>
<tr>
	<td>VEX.DDS.256.66.0F38.W0 93 /r VGATHERQPS<em> xmm1, vm64y, xmm2</em></td>
	<td>RMV</td>
	<td>V/V</td>
	<td>AVX2</td>
	<td>Using qword indices specified in <em>vm64y</em>, gather single-precision FP values from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td>
</tr>
</table>
<h2 id="instruction-operand-encoding">Instruction Operand Encoding</h2>
<table>
<tr>
	<td>Op/En</td>
	<td>Operand 1</td>
	<td>Operand 2</td>
	<td>Operand 3</td>
	<td>Operand 4</td>
</tr>
<tr>
	<td>A</td>
	<td>ModRM:reg (r,w)</td>
	<td>BaseReg (R): VSIB:base, VectorReg(R): VSIB:index</td>
	<td>VEX.vvvv (r, w)</td>
	<td>NA</td>
</tr>
</table>
<h2 id="description">Description</h2>
<p>The instruction conditionally loads up to 4 or 8 single-precision floating-point values from memory addresses specified by the memory operand (the second operand) and using dword indices. The memory operand uses the VSIB form of the SIB byte to specify a general purpose register operand as the common base, a vector register for an array of indices relative to the base and a constant scale factor. The mask operand (the third operand) specifies the conditional load operation from each memory address and the corresponding update of each data element of the destination operand (the first operand). Conditionality is specified by the most significant bit of each data element of the mask register. If an element’s mask bit is not set, the corresponding element of the destination register is left unchanged. The width of data element in the destination register and mask register are identical. The entire mask register will be set to zero by this instruction unless the instruction causes an exception. Using qword indices, the instruction conditionally loads up to 2 or 4 single-precision floating-point values from the VSIB addressing memory operand, and updates the lower half of the destination register. The upper 128 or 256 bits of the destination register are zero’ed with qword indices. This instruction can be suspended by an exception if at least one element is already gathered (i.e., if the exception</p>
<table>
<tr>
	<td>is triggered by an element other than the rightmost one with its mask bit set). register and the mask operand are partially updated; those elements that have been gathered are placed into the destination register and have their mask bits set to zero. ered elements, they will be delivered in lieu of the exception; in this case, EFLAG.RF is set to one so an instruction breakpoint is not re-triggered when the instruction is continued. If the data size and index size are different, part of the destination register and part of the mask register do not correspond to any elements being gathered. of those registers even if the instruction triggers an exception, and even if the instruction triggers the exception before gathering any elements.</td>
	<td>When this happens, the destination If any traps or interrupts are pending from already gathIt may do this to one or both</td>
</tr>
<tr>
	<td>VEX.128 version: For dword indices, the instruction will gather four single-precision floating-point values.</td>
	<td>For</td>
</tr>
</table>
<p>qword indices, the instruction will gather two values and zeroes the upper 64 bits of the destination.</p>
<table>
<tr>
	<td>VEX.256 version: For dword indices, the instruction will gather eight single-precision floating-point values. qword indices, the instruction will gather four values and zeroes the upper 128 bits of the destination. Note that: •</td>
	<td>For If any pair of the index, mask, or destination registers are the same, this instruction results a UD fault.</td>
</tr>
<tr>
	<td>•64 memory-ordering model. •</td>
	<td>Memory ordering with other instructions follows the IntelThat is, if a fault is triggered by an element and delivered, all</td>
</tr>
<tr>
	<td>elements closer to the LSB of the destination will be completed (and non-faulting). to the MSB may or may not be completed. conventional order. •</td>
	<td>Individual elements closer If a given element triggers multiple faults, they are delivered in the Elements may be gathered in any order, but faults must be delivered in a right-to-left order; thus, elements to</td>
</tr>
<tr>
	<td>the left of a faulting one may be gathered before the fault is delivered. instruction is repeatable - given the same input values and architectural state, the same set of elements to the left of the faulting one will be gathered. •</td>
	<td>A given implementation of this This instruction does not perform AC checks, and so will never deliver an AC fault.</td>
</tr>
<tr>
	<td>•</td>
	<td>This instruction will cause a #UD if the address size attribute is 16-bit.</td>
</tr>
<tr>
	<td>•</td>
	<td>This instruction will cause a #UD if the memory operand is encoded without the SIB byte.</td>
</tr>
<tr>
	<td>•is implementation specific, and some implementations may use loads larger than the data element size or load elements an indeterminate number of times. •</td>
	<td>This instruction should not be used to access memory mapped I/O as the ordering of the individual loads it does The scaled index may require more bits to represent than the address bits used by the processor (e.g., in 32-</td>
</tr>
<tr>
	<td>bit mode, if the scale is greater than one). bits are ignored.</td>
	<td>In this case, the most significant bits beyond the number of address</td>
</tr>
</table>
<h2 id="operation">Operation</h2>
<pre>DEST ← SRC1;
BASE_ADDR: base register encoded in VSIB addressing;
VINDEX: the vector index register encoded by VSIB addressing;
SCALE: scale factor encoded by SIB:[7:6];
DISP: optional 1, 4 byte displacement;
MASK ← SRC3;
VGATHERDPS (VEX.128 version)
FOR j← 0 to 3
  i ← j * 32;
  IF MASK[31+i] THEN
     MASK[i +31:i] ← 0xFFFFFFFF; // extend from most significant bit
  ELSE
     MASK[i +31:i] ← 0;
  FI;
ENDFOR
MASK[VLMAX-1:128] ← 0;
FOR j← 0 to 3
  i ← j * 32;
  DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX[i+31:i])*SCALE + DISP;
  IF MASK[31+i] THEN
     DEST[i +31:i] ← FETCH_32BITS(DATA_ADDR); // a fault exits the instruction
  FI;
  MASK[i +31:i] ← 0;
ENDFOR
DEST[VLMAX-1:128] ← 0;
(non-masked elements of the mask register have the content of respective element
VGATHERQPS (VEX.128 version)
FOR j← 0 to 3
  i ← j * 32;
  IF MASK[31+i] THEN
     MASK[i +31:i] ← 0xFFFFFFFF; // extend from most significant bit
  ELSE
     MASK[i +31:i] ← 0;
  FI;
ENDFOR
MASK[VLMAX-1:128] ← 0;
FOR j← 0 to 1
  k ← j * 64;
  i ← j * 32;
  DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[k+63:k])*SCALE + DISP;
  IF MASK[31+i] THEN
     DEST[i +31:i] ← FETCH_32BITS(DATA_ADDR); // a fault exits the instruction
  FI;
  MASK[i +31:i] ← 0;
ENDFOR
MASK[127:64] ← 0;
DEST[VLMAX-1:64] ← 0;
(non-masked elements of the mask register have the content of respective element
VGATHERDPS (VEX.256 version)
FOR j← 0 to 7
  i ← j * 32;
  IF MASK[31+i] THEN
     MASK[i +31:i] ← 0xFFFFFFFF; // extend from most significant bit
  ELSE
     MASK[i +31:i] ← 0;
  FI;
ENDFOR
FOR j← 0 to 7
  i ← j * 32;
  DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[i+31:i])*SCALE + DISP;
  IF MASK[31+i] THEN
     DEST[i +31:i] ← FETCH_32BITS(DATA_ADDR); // a fault exits the instruction
  FI;
  MASK[i +31:i] ← 0;
ENDFOR
(non-masked elements of the mask register have the content of respective element
VGATHERQPS (VEX.256 version)
FOR j← 0 to 7
  i ← j * 32;
  IF MASK[31+i] THEN
     MASK[i +31:i] ← 0xFFFFFFFF; // extend from most significant bit
  ELSE
     MASK[i +31:i] ← 0;
  FI;
ENDFOR
FOR j← 0 to 3
  k ← j * 64;
  i ← j * 32;
  DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[k+63:k])*SCALE + DISP;
  IF MASK[31+i] THEN
     DEST[i +31:i] ← FETCH_32BITS(DATA_ADDR); // a fault exits the instruction
  FI;
  MASK[i +31:i] ← 0;
ENDFOR
MASK[VLMAX-1:128] ← 0;
DEST[VLMAX-1:128] ← 0;
(non-masked elements of the mask register have the content of respective element
</pre>
<h2 id="intel-c-c-compiler-intrinsic-equivalent">Intel C/C++ Compiler Intrinsic Equivalent</h2>
<table>
<tr>
	<td>VGATHERDPS:</td>
	<td>__m128 _mm_i32gather_ps (float const * base, __m128i index, const int scale);</td>
</tr>
<tr>
	<td>VGATHERDPS:</td>
	<td>__m128 _mm_mask_i32gather_ps (__m128 src, float const * base, __m128i index, __m128 mask, const int scale);</td>
</tr>
<tr>
	<td>VGATHERDPS:</td>
	<td>__m256 _mm256_i32gather_ps (float const * base, __m256i index, const int scale);</td>
</tr>
<tr>
	<td>VGATHERDPS: scale);</td>
	<td>__m256 _mm256_mask_i32gather_ps (__m256 src, float const * base, __m256i index, __m256 mask, const int</td>
</tr>
<tr>
	<td>VGATHERQPS:</td>
	<td>__m128 _mm_i64gather_ps (float const * base, __m128i index, const int scale);</td>
</tr>
<tr>
	<td>VGATHERQPS:</td>
	<td>__m128 _mm_mask_i64gather_ps (__m128 src, float const * base, __m128i index, __m128 mask, const int scale);</td>
</tr>
<tr>
	<td>VGATHERQPS:</td>
	<td>__m128 _mm256_i64gather_ps (float const * base, __m256i index, const int scale);</td>
</tr>
<tr>
	<td>VGATHERQPS: scale);</td>
	<td>__m128 _mm256_mask_i64gather_ps (__m128 src, float const * base, __m256i index, __m128 mask, const int</td>
</tr>
</table>
<h2 id="simd-floating-point-exceptions">SIMD Floating-Point Exceptions</h2>
<p>None</p>
<h2 id="other-exceptions">Other Exceptions</h2>
<p>See Exceptions Type 12</p>
</body>
</html>
